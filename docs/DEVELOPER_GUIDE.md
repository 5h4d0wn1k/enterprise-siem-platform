# Enterprise SIEM Platform - Developer Guide

This guide is intended for developers who want to extend, enhance, or integrate with the Enterprise SIEM Platform. It covers the core architecture, components, and provides examples of how to create custom collectors, analyzers, and alerters.

## Table of Contents

1. [Architecture Overview](#architecture-overview)
2. [Core Components](#core-components)
3. [Adding a Custom Collector](#adding-a-custom-collector)
4. [Creating a Custom Analyzer](#creating-a-custom-analyzer)
5. [Implementing a New Alerter](#implementing-a-new-alerter)
6. [Working with Events](#working-with-events)
7. [Dashboard Customization](#dashboard-customization)
8. [Testing Your Extensions](#testing-your-extensions)
9. [Common Patterns and Best Practices](#common-patterns-and-best-practices)
10. [API Reference](#api-reference)

## Architecture Overview

The Enterprise SIEM Platform follows a modular, event-driven architecture with the following high-level flow:

1. **Collectors** gather log data from various sources
2. **Events** are created from the collected data and placed in the event queue
3. **Analyzers** process events from the queue, applying detection rules
4. **Alerts** are generated when rules trigger and placed in the alert queue
5. **Alerters** consume alerts from the queue and deliver notifications
6. The **Dashboard** provides visualization and reporting

Each component runs in its own thread and communicates via thread-safe queues. This architecture allows for:

- Independent scaling of components
- Easy addition of new components
- Fault isolation (a failure in one component doesn't crash the entire system)
- Real-time processing of events

## Core Components

### Event Class

The `Event` class is the central data structure used throughout the platform:

```python
from src.utils.event import Event

# Create an event
event = Event(
    source="windows_security_log",
    event_type="authentication",
    message="Failed login attempt for user admin",
    severity="medium",
    raw_data={"user": "admin", "attempt_count": 3, "source_ip": "192.168.1.100"},
    timestamp=datetime.datetime.now()
)
```

Key methods:
- `to_dict()` - Convert event to a dictionary for serialization
- `from_dict(data)` - Create an event from a dictionary 
- `__str__()` - String representation for logging

### BaseCollector

All collectors inherit from the `BaseCollector` class:

```python
from src.collectors.base_collector import BaseCollector

class BaseCollector:
    def __init__(self, config):
        self.config = config
        self.name = "base_collector"  # Override in subclass
        
    def collect_events(self, event_queue):
        """Main collection method to be implemented by subclasses."""
        pass
        
    def run_collector(self, event_queue):
        """Run the collector in a loop, handling errors."""
        # Implementation details
```

### BaseAnalyzer

Analyzers inherit from the `BaseAnalyzer` class:

```python
from src.analyzers.base_analyzer import BaseAnalyzer

class BaseAnalyzer:
    def __init__(self, config):
        self.config = config
        self.name = "base_analyzer"  # Override in subclass
        
    def analyze_event(self, event):
        """Analyze a single event and return alerts if any."""
        pass
        
    def run_analyzer(self, event_queue, alert_queue):
        """Run the analyzer in a loop, consuming from event_queue and producing to alert_queue."""
        # Implementation details
```

### BaseAlerter

Alerters inherit from the `BaseAlerter` class:

```python
from src.alerting.base_alerter import BaseAlerter

class BaseAlerter:
    def __init__(self, config):
        self.config = config
        self.name = "base_alerter"  # Override in subclass
        
    def send_alert(self, alert):
        """Send a single alert."""
        pass
        
    def run_alerter(self, alert_queue):
        """Run the alerter in a loop, consuming from alert_queue."""
        # Implementation details
```

### Alert Class

The `Alert` class represents security alerts generated by analyzers:

```python
from src.utils.alert import Alert

alert = Alert(
    title="Multiple Failed Logins",
    message="3 failed login attempts for user admin",
    severity="high",
    source="threshold_analyzer",
    events=[event1, event2, event3],  # Related events
    timestamp=datetime.datetime.now()
)
```

## Adding a Custom Collector

To add a custom collector, create a new file in the `src/collectors` directory:

```python
# src/collectors/custom_collector.py
import logging
import time
from src.collectors.base_collector import BaseCollector
from src.utils.event import Event

class CustomCollector(BaseCollector):
    def __init__(self, config):
        super().__init__(config)
        self.name = "custom_collector"
        self.logger = logging.getLogger(__name__)
        
        # Extract configuration settings
        self.interval = config.get('interval', 60)  # Default: check every 60 seconds
        self.source_name = config.get('source_name', 'custom_source')
        
        # Initialize any resources needed
        # self.client = SomeAPIClient(config.get('api_key'))
        
    def collect_events(self, event_queue):
        """
        Collect events from the custom source and add them to the event queue.
        
        Args:
            event_queue (Queue): Queue to place collected events
        """
        self.logger.info(f"Collecting events from {self.source_name}")
        
        try:
            # Fetch data from your source
            # raw_data = self.client.get_latest_data()
            
            # For this example, we'll just create a sample event
            raw_data = {"sample": "data", "timestamp": time.time()}
            
            # Create an event
            event = Event(
                source=self.source_name,
                event_type="custom_event",
                message="Sample event from custom collector",
                severity="low",
                raw_data=raw_data
            )
            
            # Add to queue
            event_queue.put(event)
            self.logger.debug(f"Added event to queue: {event}")
            
            # Sleep for the configured interval
            time.sleep(self.interval)
            
        except Exception as e:
            self.logger.error(f"Error collecting events: {str(e)}")
            # Sleep on error to prevent rapid failure loops
            time.sleep(5)
```

Then register your collector in the configuration file:

```yaml
# config.yaml
collectors:
  custom_collector:
    enabled: true
    interval: 30
    source_name: my_custom_source
    # Other configuration options for your collector
```

And update the collector initialization in `run_siem.py`:

```python
# Import your collector
from src.collectors.custom_collector import CustomCollector

# Later in the code where collectors are initialized:
if config['collectors'].get('custom_collector', {}).get('enabled', False):
    collector = CustomCollector(config['collectors'].get('custom_collector', {}))
    collector_threads.append(
        threading.Thread(
            target=collector.run_collector,
            args=(event_queue,),
            daemon=True
        )
    )
```

## Creating a Custom Analyzer

To create a custom analyzer, add a new file in the `src/analyzers` directory:

```python
# src/analyzers/custom_analyzer.py
import logging
from src.analyzers.base_analyzer import BaseAnalyzer
from src.utils.alert import Alert

class CustomAnalyzer(BaseAnalyzer):
    def __init__(self, config):
        super().__init__(config)
        self.name = "custom_analyzer"
        self.logger = logging.getLogger(__name__)
        
        # Extract configuration settings
        self.rules = config.get('rules', [])
        
        # Initialize any state needed for your analysis
        self.state = {}
        
    def analyze_event(self, event):
        """
        Analyze an event and generate alerts if necessary.
        
        Args:
            event (Event): The event to analyze
            
        Returns:
            list: List of Alert objects (empty if no alerts generated)
        """
        alerts = []
        
        # Example: Alert on any critical events
        if event.severity == "critical":
            alert = Alert(
                title="Critical Event Detected",
                message=f"Critical event from {event.source}: {event.message}",
                severity="high",
                source=self.name,
                events=[event]
            )
            alerts.append(alert)
            
        # Custom analysis logic goes here
        # ...
        
        return alerts
```

Register your analyzer in the configuration and initialization similar to the collector example.

## Implementing a New Alerter

To create a custom alerter, add a new file in the `src/alerting` directory:

```python
# src/alerting/custom_alerter.py
import logging
import json
import requests
from src.alerting.base_alerter import BaseAlerter

class WebhookAlerter(BaseAlerter):
    def __init__(self, config):
        super().__init__(config)
        self.name = "webhook_alerter"
        self.logger = logging.getLogger(__name__)
        
        # Extract configuration settings
        self.webhook_url = config.get('webhook_url')
        if not self.webhook_url:
            raise ValueError("webhook_url is required for WebhookAlerter")
        
        self.headers = config.get('headers', {
            'Content-Type': 'application/json'
        })
        
    def send_alert(self, alert):
        """
        Send an alert to a webhook endpoint.
        
        Args:
            alert (Alert): The alert to send
            
        Returns:
            bool: True if successful, False otherwise
        """
        try:
            # Format alert data
            alert_data = {
                'title': alert.title,
                'message': alert.message,
                'severity': alert.severity,
                'timestamp': alert.timestamp.isoformat(),
                'source': alert.source,
                'events': [event.to_dict() for event in alert.events]
            }
            
            # Send to webhook
            response = requests.post(
                self.webhook_url,
                headers=self.headers,
                data=json.dumps(alert_data),
                timeout=10
            )
            
            if response.status_code >= 200 and response.status_code < 300:
                self.logger.info(f"Alert sent to webhook: {alert.title}")
                return True
            else:
                self.logger.error(f"Failed to send alert to webhook. Status: {response.status_code}, Response: {response.text}")
                return False
                
        except Exception as e:
            self.logger.error(f"Error sending alert to webhook: {str(e)}")
            return False
```

## Working with Events

The Event class is the foundation of the system. Here are common patterns for working with events:

### Creating Events

```python
from src.utils.event import Event
import datetime

# Basic event creation
event = Event(
    source="firewall",
    event_type="connection",
    message="Connection blocked from external IP",
    severity="medium",
    raw_data={"src_ip": "203.0.113.42", "dst_port": 22, "action": "block"},
    timestamp=datetime.datetime.now()
)

# Creating an event from a dictionary (useful when deserializing)
event_dict = {
    "source": "ids",
    "event_type": "intrusion",
    "message": "Potential SQL injection detected",
    "severity": "high",
    "raw_data": {"payload": "SELECT * FROM users", "rule_id": "SQL-001"},
    "timestamp": "2023-04-15T14:30:10.123456"
}
event = Event.from_dict(event_dict)
```

### Serializing Events

```python
# Convert event to dictionary
event_dict = event.to_dict()

# Save events to JSON
import json
with open("events.json", "w") as f:
    json.dump([e.to_dict() for e in events], f)
```

### Working with Event Queues

```python
import queue
import threading
import time

# Create a queue
event_queue = queue.Queue()

# Add events to the queue
event_queue.put(event)

# Process events from the queue in a thread
def process_events(event_queue):
    while True:
        try:
            # Get event from queue, with timeout to allow for graceful shutdown
            event = event_queue.get(timeout=1.0)
            
            # Process the event
            print(f"Processing event: {event}")
            
            # Mark the task as done
            event_queue.task_done()
            
        except queue.Empty:
            # Queue is empty, wait a bit
            time.sleep(0.1)
        except Exception as e:
            print(f"Error processing event: {str(e)}")

# Start the processing thread
thread = threading.Thread(target=process_events, args=(event_queue,), daemon=True)
thread.start()
```

## Dashboard Customization

The dashboard is a Flask application that can be extended with new views, charts, and functionality.

### Adding a New Dashboard View

1. Create a new template in `src/dashboard/templates/`:

```html
<!-- src/dashboard/templates/custom_view.html -->
{% extends "base.html" %}

{% block content %}
<div class="container">
    <h1>Custom Dashboard View</h1>
    
    <div class="card">
        <div class="card-header">
            Custom Data
        </div>
        <div class="card-body">
            <div id="custom-chart"></div>
        </div>
    </div>
</div>

<script>
// Custom JavaScript for your view
document.addEventListener('DOMContentLoaded', function() {
    // Initialize charts or other functionality
    const data = {{ custom_data|tojson }};
    
    Plotly.newPlot('custom-chart', [{
        x: data.map(item => item.x),
        y: data.map(item => item.y),
        type: 'bar'
    }]);
});
</script>
{% endblock %}
```

2. Add a route in `src/dashboard/app.py`:

```python
@app.route('/custom')
def custom_view():
    # Get your custom data
    custom_data = [
        {"x": "Category A", "y": 10},
        {"x": "Category B", "y": 15},
        {"x": "Category C", "y": 8}
    ]
    
    return render_template('custom_view.html', custom_data=custom_data)
```

3. Add a link to the navigation menu in `base.html`:

```html
<nav class="navbar navbar-expand-lg navbar-dark bg-dark">
    <!-- ... existing navigation ... -->
    <ul class="navbar-nav mr-auto">
        <li class="nav-item">
            <a class="nav-link" href="/">Home</a>
        </li>
        <li class="nav-item">
            <a class="nav-link" href="/events">Events</a>
        </li>
        <li class="nav-item">
            <a class="nav-link" href="/alerts">Alerts</a>
        </li>
        <li class="nav-item">
            <a class="nav-link" href="/custom">Custom View</a>
        </li>
    </ul>
</nav>
```

## Testing Your Extensions

### Unit Testing

We recommend using pytest for testing your components. Here's a simple example for testing a custom collector:

```python
# tests/test_custom_collector.py
import pytest
import queue
from unittest.mock import patch, MagicMock
from src.collectors.custom_collector import CustomCollector

def test_custom_collector_init():
    # Test initialization with default config
    config = {}
    collector = CustomCollector(config)
    assert collector.name == "custom_collector"
    assert collector.interval == .60  # Default value
    
    # Test with custom config
    custom_config = {"interval": 30, "source_name": "test_source"}
    collector = CustomCollector(custom_config)
    assert collector.interval == 30
    assert collector.source_name == "test_source"

def test_collect_events():
    # Create a mock event queue
    event_queue = queue.Queue()
    
    # Create the collector
    collector = CustomCollector({"interval": 0})  # Set interval to 0 to skip the sleep
    
    # Collect events
    collector.collect_events(event_queue)
    
    # Check that an event was added to the queue
    assert event_queue.qsize() == 1
    
    # Check the event properties
    event = event_queue.get()
    assert event.source == "custom_source"
    assert event.event_type == "custom_event"
    assert event.severity == "low"
```

### Integration Testing

You can use the test data generator to test your components in an integrated fashion:

```python
# Test script for integration testing
from src.utils.test_data_generator import generate_random_event
from your_custom_analyzer import CustomAnalyzer
import queue
import time

# Create test components
analyzer = CustomAnalyzer({"your_config": "here"})
event_queue = queue.Queue()
alert_queue = queue.Queue()

# Start the analyzer in a thread
import threading
analyzer_thread = threading.Thread(
    target=analyzer.run_analyzer,
    args=(event_queue, alert_queue),
    daemon=True
)
analyzer_thread.start()

# Generate and add test events
for _ in range(10):
    event = generate_random_event(severity="high")  # Generate a high severity event
    event_queue.put(event)
    time.sleep(0.1)

# Check for alerts
time.sleep(1)  # Give the analyzer time to process
alert_count = alert_queue.qsize()
print(f"Generated {alert_count} alerts")

# Process all alerts
while not alert_queue.empty():
    alert = alert_queue.get()
    print(f"Alert: {alert.title} - {alert.message}")
```

## Common Patterns and Best Practices

### Error Handling

Always handle exceptions in your components to prevent them from crashing:

```python
try:
    # Your code that might raise exceptions
    result = do_something_risky()
except Exception as e:
    # Log the error
    self.logger.error(f"Error in component: {str(e)}")
    # Optionally, include traceback for debugging
    import traceback
    self.logger.debug(f"Traceback: {traceback.format_exc()}")
    # Return a safe default or re-raise if critical
    return default_value
```

### Logging

Use the logging module consistently:

```python
import logging

# Get a logger for your module
logger = logging.getLogger(__name__)

# Use appropriate log levels
logger.debug("Detailed information for debugging")
logger.info("General information about operation")
logger.warning("Something unexpected but not critical")
logger.error("An error that prevents normal operation")
logger.critical("A critical error that may cause system failure")
```

### Configuration

Make your components configurable:

```python
def __init__(self, config):
    # Set defaults then override with provided config
    self.interval = 60
    self.batch_size = 100
    self.severity_threshold = "medium"
    
    # Override defaults with provided config
    if 'interval' in config:
        self.interval = config['interval']
    if 'batch_size' in config:
        self.batch_size = config['batch_size']
    if 'severity_threshold' in config:
        self.severity_threshold = config['severity_threshold']
```

Or more concisely:

```python
def __init__(self, config):
    # Set defaults then override with provided config
    self.interval = config.get('interval', 60)
    self.batch_size = config.get('batch_size', 100)
    self.severity_threshold = config.get('severity_threshold', "medium")
```

### Resource Management

Always clean up resources:

```python
def __init__(self, config):
    # Initialize resources
    self.connection = self.create_connection(config)
    
def create_connection(self, config):
    # Create and return a connection resource
    pass
    
def cleanup(self):
    # Clean up resources
    if hasattr(self, 'connection') and self.connection:
        try:
            self.connection.close()
        except Exception as e:
            self.logger.error(f"Error closing connection: {str(e)}")
```

## API Reference

For detailed API documentation of the core components, refer to:

- [Event API Reference](EVENT_API_REFERENCE.md)
- [Collector API Reference](COLLECTOR_API_REFERENCE.md)
- [Analyzer API Reference](ANALYZER_API_REFERENCE.md)
- [Alerter API Reference](ALERTER_API_REFERENCE.md)
- [Dashboard API Reference](DASHBOARD_API_REFERENCE.md)

## Examples

For complete example implementations, see the `examples/` directory, which includes:

- `api_example.py` - Demonstrates programmatic use of the platform
- `custom_collector_example.py` - Example custom collector implementation
- `custom_analyzer_example.py` - Example custom analyzer implementation
- `custom_alerter_example.py` - Example custom alerter implementation

## Getting Help

If you encounter issues or have questions about extending the platform, please:

1. Check the documentation
2. Look for similar issues in the issue tracker
3. Open a new issue with detailed information about your problem
4. Contact the development team